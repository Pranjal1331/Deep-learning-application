{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXaWfOQbYXJq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Final Assignment: Data driven approach to laminar and turbulent flow classification\n",
        "\n",
        "Laminar flow has been characterized for its smooth and linear behavior concerning its flow.\n",
        "When a non-linearity is introduced, the flow becomes turbulent.\n",
        "Visually it is possible to distinguish between laminar and turbulent flow by\n",
        "identifying areas in the flow that become chaotic or non-smooth.\n",
        "We used a Convolutional Neural Network (CNN) trained on labeled laminar and\n",
        "turbulent images to automate the process. In this assignment, we take simulated\n",
        "contours from a flow past cylinder simulation, train it, and test it to see how\n",
        "effective the CNN is at distinguishing between the laminar and turbulent flow.\n",
        "The geometry is as follows -\n",
        "There is a circular cylinder axis along the z-axis(out of the plane),\n",
        "you have to simulate 2d velocity profile about it.\n",
        "\n",
        "Objective of CNN model is that given a simulated velocity profile,\n",
        "it should be able to efficiently predict the nature of fluid flow.\n",
        "Compare the accuracy of different CNN architectures covered in the class and\n",
        "based on that choose a model of your dataset.\n",
        "Then optimize hyperparameters to get accuracy more than 80%\n",
        "\n",
        " Deadline to the assignment is : 10th May\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1. create  and preprocess\n",
        "- 10 laminar/10 turbulent images for dataset\n",
        "- preprocess - resize, normalise\n",
        "2. try some cnns\n",
        "3. optimise hyperparameters (80% accuracy)\n",
        "4. documentation\n",
        "'''"
      ],
      "metadata": {
        "id": "QQ1FgHmoK4bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "proKANujdQti"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting a seed to ensure reproducibility\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "R5hK4J3BNW6b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "\n",
        "print(\"GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "laminar_dir = \"/content/drive/MyDrive/Fluid_flow_data/laminar\"\n",
        "laminar_dir_p = \"/content/drive/MyDrive/Fluid_flow_data/laminarp\"\n",
        "\n",
        "turbulant_dir = \"/content/drive/MyDrive/Fluid_flow_data/turbulent\"\n",
        "turbulant_dir_p = \"/content/drive/MyDrive/Fluid_flow_data/turbulantp\"\n",
        "\n",
        "#source_dir = \"/content/drive/MyDrive/Fluid_flow_data\"\n",
        "train_dir = \"/content/drive/MyDrive/Fluid_flow_data/train\"\n",
        "test_dir = \"/content/drive/MyDrive/Fluid_flow_data/test\"\n",
        "val_dir = \"/content/drive/MyDrive/Fluid_flow_data/validation\"\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(laminar_dir_p, exist_ok=True)\n",
        "os.makedirs(turbulant_dir_p, exist_ok=True)\n",
        "\n",
        "lamtrain = os.path.join(train_dir, \"laminar\")\n",
        "lamtest = os.path.join(test_dir, \"laminar\")\n",
        "lamval = os.path.join(val_dir, \"laminar\")\n",
        "\n",
        "turtrain = os.path.join(train_dir, \"turbulant\")\n",
        "turtest = os.path.join(test_dir, \"turbulant\")\n",
        "turval = os.path.join(val_dir, \"turbulant\")\n",
        "\n",
        "os.makedirs(lamtrain, exist_ok=True)\n",
        "os.makedirs(lamtest, exist_ok=True)\n",
        "os.makedirs(lamval, exist_ok=True)\n",
        "os.makedirs(turtrain, exist_ok=True)\n",
        "os.makedirs(turtest, exist_ok=True)\n",
        "os.makedirs(turval, exist_ok=True)\n",
        "\n",
        "#train_dir = r\"/content/drive/MyDrive/Fluid_flow_data\"\n"
      ],
      "metadata": {
        "id": "bOHLMSm8NaIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d2684fc-e1a9-4895-ae7f-6cc7d108ce15"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUs Available:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 224, 224\n",
        "num_classes = 2\n",
        "batchsize = 10"
      ],
      "metadata": {
        "id": "IWbKdk6_yquu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to preprocess images\n",
        "def preprocess_images(source_dir, target_dir):\n",
        "      for file in os.listdir(source_dir):\n",
        "          # load image\n",
        "          img = load_img(os.path.join(source_dir, file), target_size=(img_width, img_height))\n",
        "          img_array = img_to_array(img)\n",
        "          img_array /= 255.0  # normalize pixel values\n",
        "          # move preprocessed image to target directory\n",
        "          # os.rename(os.path.join(subdir, file), os.path.join(target_dir, subdir.split('/')[-1] + '_' + file))\n",
        "          os.rename(os.path.join(source_dir, file), os.path.join(target_dir, file))\n",
        "\n",
        "preprocess_images(laminar_dir, laminar_dir_p)\n",
        "preprocess_images(turbulant_dir, turbulant_dir_p)"
      ],
      "metadata": {
        "id": "E8evOYDyeolH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into train, test, and validation\n",
        "laminar_files = os.listdir(laminar_dir_p)\n",
        "turbulent_files = os.listdir(turbulant_dir_p)\n",
        "\n",
        "laminar_train, laminar_test_val = train_test_split(laminar_files, test_size=0.3, random_state=42)\n",
        "laminar_test, laminar_val = train_test_split(laminar_test_val, test_size=0.5, random_state=42)\n",
        "\n",
        "turbulent_train, turbulent_test_val = train_test_split(turbulent_files, test_size=0.3, random_state=42)\n",
        "turbulent_test, turbulent_val = train_test_split(turbulent_test_val, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "2axAVt-4w0Dk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_files(source_files, source_dir, dest_dir):\n",
        "    for file in source_files:\n",
        "        #os.rename(os.path.join(source_dir, file), os.path.join(dest_dir, file))\n",
        "        os.rename(os.path.join(source_dir, file), os.path.join(dest_dir, file))"
      ],
      "metadata": {
        "id": "PCyJimPk2me5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move files to appropriate directories\n",
        "\n",
        "move_files(laminar_train, laminar_dir_p, os.path.join(train_dir, \"laminar\"))\n",
        "move_files(laminar_test, laminar_dir_p, os.path.join(test_dir, \"laminar\"))\n",
        "move_files(laminar_val, laminar_dir_p, os.path.join(val_dir, \"laminar\"))\n",
        "\n",
        "move_files(turbulent_train, turbulant_dir_p, os.path.join(train_dir, \"turbulant\"))\n",
        "move_files(turbulent_test, turbulant_dir_p, os.path.join(test_dir, \"turbulant\"))\n",
        "move_files(turbulent_val, turbulant_dir_p, os.path.join(val_dir, \"turbulant\"))\n"
      ],
      "metadata": {
        "id": "Njx0_cfRnm1A"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding\n",
        "# 0 - laminar\n",
        "# 1 - turbulent\n",
        "\n",
        "# train\n",
        "train_files = []\n",
        "train_files.extend([os.path.join(lamtrain, file) for file in laminar_train])\n",
        "train_files.extend([os.path.join(turtrain, file) for file in turbulent_train])\n",
        "\n",
        "train_labels = []\n",
        "train_labels.extend([0] * len(laminar_train))\n",
        "train_labels.extend([1] * len(turbulent_train))\n",
        "\n",
        "train_labels = to_categorical(train_labels, 2)\n",
        "\n",
        "# test\n",
        "test_files = []\n",
        "test_files.extend([os.path.join(lamtest, file) for file in laminar_test])\n",
        "test_files.extend([os.path.join(turtest, file) for file in turbulent_test])\n",
        "\n",
        "test_labels = []\n",
        "test_labels.extend([0] * len(laminar_test))\n",
        "test_labels.extend([1] * len(turbulent_test))\n",
        "\n",
        "test_labels = to_categorical(test_labels, 2)\n",
        "\n",
        "# validation\n",
        "val_files = []\n",
        "val_files.extend([os.path.join(lamval, file) for file in laminar_val])\n",
        "val_files.extend([os.path.join(turval, file) for file in turbulent_val])\n",
        "\n",
        "val_labels = []\n",
        "val_labels.extend([0] * len(laminar_val))\n",
        "val_labels.extend([1] * len(turbulent_val))\n",
        "\n",
        "val_labels = to_categorical(val_labels,2)\n"
      ],
      "metadata": {
        "id": "V1DPpQxHPoG3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "\n",
        "model1 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# compiling the model\n",
        "model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "2i1oHYLbNgM_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess images\n",
        "train_images = []\n",
        "\n",
        "for file in train_files:\n",
        "\n",
        "    img = load_img(file, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    train_images.append(img_array)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "val_images = []\n",
        "\n",
        "for file in val_files:\n",
        "\n",
        "    img = load_img(file, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    val_images.append(img_array)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "val_images = np.array(val_images)\n",
        "val_labels = np.array(val_labels)\n"
      ],
      "metadata": {
        "id": "t-OWU7lM5gkg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "K.clear_session()\n"
      ],
      "metadata": {
        "id": "i8Sf2ACi7bv4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model\n",
        "history = model1.fit(train_images, train_labels, batch_size = 15, validation_data=(val_images, val_labels), epochs=5)\n"
      ],
      "metadata": {
        "id": "8w3TF8PA_gaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29735997-ceea-4904-f1ea-3a8ecc669ee6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "14/14 [==============================] - 39s 3s/step - loss: 378.2673 - accuracy: 0.6139 - val_loss: 16.7579 - val_accuracy: 0.6444\n",
            "Epoch 2/5\n",
            "14/14 [==============================] - 35s 3s/step - loss: 3.8059 - accuracy: 0.7871 - val_loss: 0.4734 - val_accuracy: 0.7111\n",
            "Epoch 3/5\n",
            "14/14 [==============================] - 35s 3s/step - loss: 0.3834 - accuracy: 0.8416 - val_loss: 0.4068 - val_accuracy: 0.8667\n",
            "Epoch 4/5\n",
            "14/14 [==============================] - 37s 3s/step - loss: 0.1123 - accuracy: 0.9653 - val_loss: 0.2585 - val_accuracy: 0.8889\n",
            "Epoch 5/5\n",
            "14/14 [==============================] - 35s 2s/step - loss: 0.0809 - accuracy: 0.9653 - val_loss: 0.5230 - val_accuracy: 0.9111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "\n",
        "for file in test_files:\n",
        "\n",
        "    img = load_img(file, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    test_images.append(img_array)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n"
      ],
      "metadata": {
        "id": "WioKfEOw82SK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "test_loss, test_accuracy = model1.evaluate(test_images, test_labels, batch_size=10)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy*100)\n",
        "\n",
        "# Predicting classes\n",
        "predictions = model1.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Generating true classes\n",
        "true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generating class labels\n",
        "class_labels = [\"laminar\", \"turbulent\"]\n",
        "\n",
        "# Generating classification report\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJQ9R7A18whv",
        "outputId": "ffd90bda-4a14-42d4-d96c-9cf17dc6a79a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 269ms/step - loss: 1.5761e-04 - accuracy: 1.0000\n",
            "Test Loss: 0.00015760649694129825\n",
            "Test Accuracy: 100.0\n",
            "2/2 [==============================] - 1s 353ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     laminar       1.00      1.00      1.00        21\n",
            "   turbulent       1.00      1.00      1.00        23\n",
            "\n",
            "    accuracy                           1.00        44\n",
            "   macro avg       1.00      1.00      1.00        44\n",
            "weighted avg       1.00      1.00      1.00        44\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "        Conv2D(96, (11,11), activation='relu', input_shape=(img_width, img_height, 3)),\n",
        "        MaxPooling2D(3,3),\n",
        "        Conv2D(256, (5,5), padding='same', activation='relu'),\n",
        "        Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "        MaxPooling2D(3,3),\n",
        "        Conv2D(384, (3,3), padding='same', activation='relu'),\n",
        "        Conv2D(384, (3,3), padding='same', activation='relu'),\n",
        "        MaxPooling2D(3,3),\n",
        "        Flatten(),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# compiling the model\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# print(model.summary())\n"
      ],
      "metadata": {
        "id": "Oaegs8EL-yJz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model\n",
        "history = model2.fit(train_images, train_labels, batch_size = 10, validation_data=(val_images, val_labels), epochs=4)\n"
      ],
      "metadata": {
        "id": "RME_aZdtN7uJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a80c6d-4773-49e0-ec86-b3e66e1cb80e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "21/21 [==============================] - 294s 14s/step - loss: 137.9366 - accuracy: 0.4802 - val_loss: 1.3150 - val_accuracy: 0.4444\n",
            "Epoch 2/4\n",
            "21/21 [==============================] - 300s 14s/step - loss: 0.8753 - accuracy: 0.4406 - val_loss: 0.6966 - val_accuracy: 0.4667\n",
            "Epoch 3/4\n",
            "21/21 [==============================] - 294s 14s/step - loss: 0.6964 - accuracy: 0.4455 - val_loss: 0.6936 - val_accuracy: 0.5111\n",
            "Epoch 4/4\n",
            "21/21 [==============================] - 296s 14s/step - loss: 0.7083 - accuracy: 0.4505 - val_loss: 0.6933 - val_accuracy: 0.4667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "test_loss, test_accuracy = model2.evaluate(test_images, test_labels, batch_size=10)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy*100)\n",
        "\n",
        "# Predicting classes\n",
        "predictions = model2.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Generating true classes\n",
        "true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generating class labels\n",
        "class_labels = [\"laminar\", \"turbulent\"]\n",
        "\n",
        "# Generating classification report\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n"
      ],
      "metadata": {
        "id": "b0sYs6UHOGwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105d0612-818c-4741-de7a-ae8c7bd609c2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 17s 3s/step - loss: 0.6932 - accuracy: 0.4773\n",
            "Test Loss: 0.6931898593902588\n",
            "Test Accuracy: 47.72727191448212\n",
            "2/2 [==============================] - 18s 4s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     laminar       0.48      1.00      0.65        21\n",
            "   turbulent       0.00      0.00      0.00        23\n",
            "\n",
            "    accuracy                           0.48        44\n",
            "   macro avg       0.24      0.50      0.32        44\n",
            "weighted avg       0.23      0.48      0.31        44\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LeNet5\n",
        "\n",
        "def LeNet5(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(120, activation='relu'))\n",
        "    model.add(Dense(84, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "lenet_model = LeNet5((224, 224, 3), 2)\n",
        "lenet_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "4pDLbEOm00oZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model\n",
        "history = lenet_model.fit(train_images, train_labels, batch_size = 10, validation_data=(val_images, val_labels), epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S51NeYG-1fot",
        "outputId": "1dbac2a4-60df-49e0-dace-e31a60c863c7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "21/21 [==============================] - 30s 531ms/step - loss: 101.3700 - accuracy: 0.5990 - val_loss: 1.0709 - val_accuracy: 0.6667\n",
            "Epoch 2/4\n",
            "21/21 [==============================] - 9s 440ms/step - loss: 0.5487 - accuracy: 0.8416 - val_loss: 0.5332 - val_accuracy: 0.8889\n",
            "Epoch 3/4\n",
            "21/21 [==============================] - 10s 481ms/step - loss: 0.1785 - accuracy: 0.9356 - val_loss: 0.5007 - val_accuracy: 0.8889\n",
            "Epoch 4/4\n",
            "21/21 [==============================] - 11s 550ms/step - loss: 0.0940 - accuracy: 0.9901 - val_loss: 0.8949 - val_accuracy: 0.8889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "test_loss, test_accuracy = lenet_model.evaluate(test_images, test_labels, batch_size=10)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy*100)\n",
        "\n",
        "# Predicting classes\n",
        "predictions = model1.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Generating true classes\n",
        "true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generating class labels\n",
        "class_labels = [\"laminar\", \"turbulent\"]\n",
        "\n",
        "# Generating classification report\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2RVnRCn-tRr",
        "outputId": "fec7a8db-4bef-4e77-b1c8-a3be571cde2e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 121ms/step - loss: 0.4315 - accuracy: 0.8409\n",
            "Test Loss: 0.4314837157726288\n",
            "Test Accuracy: 84.09090638160706\n",
            "2/2 [==============================] - 2s 365ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     laminar       1.00      1.00      1.00        21\n",
            "   turbulent       1.00      1.00      1.00        23\n",
            "\n",
            "    accuracy                           1.00        44\n",
            "   macro avg       1.00      1.00      1.00        44\n",
            "weighted avg       1.00      1.00      1.00        44\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alexnet\n",
        "\n",
        "def AlexNet(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "alexnet_model = AlexNet((224, 224, 3), 2)\n",
        "alexnet_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "uFqVl5sX2ctk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model\n",
        "history = alexnet_model.fit(train_images, train_labels, batch_size = 10, validation_data=(val_images, val_labels), epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9zD9TZT2sw7",
        "outputId": "0d9657ec-3e95-499e-aa5f-6dfe1e009543"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "21/21 [==============================] - 27s 1s/step - loss: 19.2408 - accuracy: 0.5050 - val_loss: 0.7057 - val_accuracy: 0.4667\n",
            "Epoch 2/4\n",
            "21/21 [==============================] - 26s 1s/step - loss: 0.6928 - accuracy: 0.5099 - val_loss: 0.6418 - val_accuracy: 0.5111\n",
            "Epoch 3/4\n",
            "21/21 [==============================] - 24s 1s/step - loss: 0.6750 - accuracy: 0.5545 - val_loss: 0.6554 - val_accuracy: 0.5111\n",
            "Epoch 4/4\n",
            "21/21 [==============================] - 25s 1s/step - loss: 0.7118 - accuracy: 0.5842 - val_loss: 0.6923 - val_accuracy: 0.5333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "test_loss, test_accuracy = alexnet_model.evaluate(test_images, test_labels, batch_size=10)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy*100)\n",
        "\n",
        "# Predicting classes\n",
        "predictions = model1.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Generating true classes\n",
        "true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generating class labels\n",
        "class_labels = [\"laminar\", \"turbulent\"]\n",
        "\n",
        "# Generating classification report\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_9voo9i-z-U",
        "outputId": "d5b5318c-e531-48f7-d2e7-576cbd5d9e76"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 175ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Test Loss: 0.6944255828857422\n",
            "Test Accuracy: 50.0\n",
            "2/2 [==============================] - 1s 292ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     laminar       1.00      1.00      1.00        21\n",
            "   turbulent       1.00      1.00      1.00        23\n",
            "\n",
            "    accuracy                           1.00        44\n",
            "   macro avg       1.00      1.00      1.00        44\n",
            "weighted avg       1.00      1.00      1.00        44\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16\n",
        "\n",
        "def VGG16(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "vgg16_model = VGG16((224, 224, 3), 2)\n",
        "vgg16_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "C_fxiWgU2yDS"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model\n",
        "history = vgg16_model.fit(train_images, train_labels, batch_size = 10, validation_data=(val_images, val_labels), epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "550MLg3_25cE",
        "outputId": "907d8b93-e753-4547-bd14-0d2c227a39c5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "21/21 [==============================] - 534s 25s/step - loss: 363.0900 - accuracy: 0.5198 - val_loss: 0.7221 - val_accuracy: 0.4667\n",
            "Epoch 2/4\n",
            "21/21 [==============================] - 537s 26s/step - loss: 0.7080 - accuracy: 0.5099 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 3/4\n",
            "21/21 [==============================] - 537s 26s/step - loss: 0.6934 - accuracy: 0.5297 - val_loss: 0.6918 - val_accuracy: 0.5333\n",
            "Epoch 4/4\n",
            "21/21 [==============================] - 529s 25s/step - loss: 0.6931 - accuracy: 0.5297 - val_loss: 0.6920 - val_accuracy: 0.5333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "test_loss, test_accuracy = vgg16_model.evaluate(test_images, test_labels, batch_size=10)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy*100)\n",
        "\n",
        "# Predicting classes\n",
        "predictions = model1.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Generating true classes\n",
        "true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generating class labels\n",
        "class_labels = [\"laminar\", \"turbulent\"]\n",
        "\n",
        "# Generating classification report\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4ABRq2n-4Ug",
        "outputId": "476d63b1-d033-40d0-995b-5996516dad94"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 29s 6s/step - loss: 0.6924 - accuracy: 0.5227\n",
            "Test Loss: 0.6924317479133606\n",
            "Test Accuracy: 52.272725105285645\n",
            "2/2 [==============================] - 1s 307ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     laminar       1.00      1.00      1.00        21\n",
            "   turbulent       1.00      1.00      1.00        23\n",
            "\n",
            "    accuracy                           1.00        44\n",
            "   macro avg       1.00      1.00      1.00        44\n",
            "weighted avg       1.00      1.00      1.00        44\n",
            "\n"
          ]
        }
      ]
    }
  ]
}